{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconocimiento Facial Basico (Regresion Logística)\n",
    "\n",
    "Ejemplo de como se puede aplicar Regresión logística para clasificar expresiones faciales.\n",
    "\n",
    "Para este caso, solo vamos a utilizar 2 clases para poder utilizar una clasificación binaria con una sigmoide.\n",
    "\n",
    "En otros notebooks se implementará softmax para el caso *multiclase*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solo vamos a leer 2 clases - sino usariamos getData( ).\n",
    "# Los datos estan en un fichero csv con la siguiente estructura:\n",
    "# - emotion - numero de 0 a 6 (0-Angry, 1-Disgust, 2-Fear, 3-Happy, 4-Sad, 5-Surprise, 6-Neutral)\n",
    "# - pixels - imagen de 48 x 48 pixels (no tiene color, solo 255 tonos de grises)\n",
    "# - Usage - training o test\n",
    "\n",
    "# Devuelve un array X( ) de todos los pixels de cada imagen \n",
    "# y un vector Y( ) con las etiquetas\n",
    "\n",
    "def getBinaryData():\n",
    "    Y = []\n",
    "    X = []\n",
    "    first = True # para saltarnos la primera linea\n",
    "    for line in open('/home/jorge/data/facial_expressions/fer2013/fer2013.csv'):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            row = line.split(',')   # separamos los datos usando la \",\"\n",
    "            y = int(row[0])         # guardo el tipo de expresion en el target\n",
    "\n",
    "            if y == 0 or y == 1:    # solo nos quedamos con estos tipos de expresion\n",
    "                Y.append(y)\n",
    "                X.append([int(p) for p in row[1].split()])\n",
    "                \n",
    "    return np.array(X) / 255.0, np.array(Y)        # Aqui normalizamos los datos X dividiendo por 255\n",
    "                                                   # entonces nos quedan entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(A):\n",
    "    return 1 / (1 + np.exp(-A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Usamos cross-entropy como funcion de coste\n",
    "def sigmoid_cost(T, Y):\n",
    "    return -(T*np.log(Y) + (1-T)*np.log(1-Y)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# La tasa de error será la media de la diferencia entre targets y predicciones\n",
    "def error_rate(targets, predictions):\n",
    "    return np.mean(targets != predictions)          # nos quedamos con la media de los que son diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticModel(object):\n",
    "    def __init__(self):            # en este caso el constructor no tiene accion\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, Y, learning_rate=10e-7, reg=0*10e-22, epochs=120000, show_fig=False):\n",
    "        X, Y = shuffle(X, Y)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "\n",
    "        N, D = X.shape\n",
    "        self.W = np.random.randn(D) / np.sqrt(D)\n",
    "        self.b = 0\n",
    "\n",
    "        costs = []\n",
    "        best_validation_error = 1\n",
    "        for i in range(epochs):\n",
    "                # forward propagation and cost calculation\n",
    "                pY = self.forward(X)\n",
    "\n",
    "                # Calculamos el descenso de gradiente para los pesos y el bias \n",
    "                self.W -= learning_rate*(X.T.dot(pY - Y) + reg*self.W)\n",
    "                self.b -= learning_rate*((pY - Y).sum() + reg*self.b)\n",
    "\n",
    "                # cada 12.000 epochs vemos la funcion de coste y el error\n",
    "                if i % 12000 == 0:\n",
    "                    pYvalid = self.forward(Xvalid)\n",
    "                    c = sigmoid_cost(Yvalid, pYvalid)\n",
    "                    costs.append(c)\n",
    "                    e = error_rate(Yvalid, np.round(pYvalid))\n",
    "                    print(\"i:\", i, \"cost:\", c, \"error:\", e)\n",
    "                    if e < best_validation_error:\n",
    "                        best_validation_error = e\n",
    "        print(\"Mejor Error de validacion:\", best_validation_error)\n",
    "\n",
    "        if show_fig:\n",
    "            plt.plot(costs)\n",
    "            plt.show()\n",
    "\n",
    "    def JEC_fit(self, X, Y, learning_rate=10e-7, reg=0*10e-22, epochs=120000):\n",
    "        X, Y = shuffle(X, Y)\n",
    "        Xvalid, Yvalid = X[-1000:], Y[-1000:]\n",
    "        X, Y = X[:-1000], Y[:-1000]\n",
    "\n",
    "        N, D = X.shape\n",
    "        self.W = np.random.randn(D) / np.sqrt(D)\n",
    "        self.b = 0\n",
    "\n",
    "        costs = []\n",
    "        best_validation_error = 1\n",
    "        for i in range(epochs):\n",
    "                # forward propagation and cost calculation\n",
    "                pY = self.forward(X)\n",
    "\n",
    "                # Calculamos el descenso de gradiente para los pesos y el bias \n",
    "                self.W -= learning_rate*(X.T.dot(pY - Y) + reg*self.W)\n",
    "                self.b -= learning_rate*((pY - Y).sum() + reg*self.b)\n",
    "\n",
    "                # cada 10000 epochs vemos la funcion de coste y el error\n",
    "                if i % 1000 == 0:\n",
    "                    pYvalid = self.forward(Xvalid)\n",
    "                    c = sigmoid_cost(Yvalid, pYvalid)\n",
    "                    costs.append(c)\n",
    "                    e = error_rate(Yvalid, np.round(pYvalid))\n",
    "                    print(\"i:\", i, \"cost:\", c, \"error:\", e)\n",
    "                    if e < best_validation_error:\n",
    "                        best_validation_error = e\n",
    "        print(\"Mejor Error de validacion:\", best_validation_error)\n",
    "        return costs\n",
    "\n",
    "    def forward(self, X):\n",
    "        return sigmoid(X.dot(self.W) + self.b)\n",
    "\n",
    "    def predict(self, X):\n",
    "        pY = self.forward(X)\n",
    "        return np.round(pY)\n",
    "\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        prediction = self.predict(X)\n",
    "        return 1 - error_rate(Y, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solo nos quedamos con 2 clases del dataset de 'Expresiones Faciales', la 0 y la 1 ((0-Angry, 1-Disgust)\n",
    "X, Y = getBinaryData()\n",
    "\n",
    "# Separamos los 2 grupos\n",
    "X0 = X[Y==0, :]\n",
    "X1 = X[Y==1, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4953, 2304)\n",
      "(547, 2304)\n"
     ]
    }
   ],
   "source": [
    "# y vemos las cantidades de cada uno\n",
    "print(X0.shape)\n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay un desbalance de clases. Una forma de solucionarlo, y para no quedarnos con menos datos, es repitiendo la clase con menos muestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4953, 2304)\n",
      "(4923, 2304)\n",
      "(9876, 2304)\n"
     ]
    }
   ],
   "source": [
    "X1 = np.repeat(X1, 9, axis=0)\n",
    "X = np.vstack([X0, X1])\n",
    "Y = np.array([0]*len(X0) + [1]*len(X1))\n",
    "\n",
    "# N, D = X.shape\n",
    "# print \"N:\", N\n",
    "# print \"p(Y=0):\", np.sum(Y == 0) / float(N), \"p(Y=1):\", np.sum(Y == 1) / float(N)\n",
    "    \n",
    "print(X0.shape)\n",
    "print(X1.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0 cost: 704.68936799 error: 0.501\n",
      "i: 1000 cost: 589.549539395 error: 0.31\n",
      "i: 2000 cost: 565.002873786 error: 0.298\n",
      "i: 3000 cost: 548.528871368 error: 0.28\n",
      "i: 4000 cost: 536.140846348 error: 0.272\n",
      "i: 5000 cost: 526.307084588 error: 0.256\n",
      "i: 6000 cost: 518.223504619 error: 0.247\n",
      "i: 7000 cost: 511.40636945 error: 0.243\n",
      "i: 8000 cost: 505.541423921 error: 0.239\n",
      "i: 9000 cost: 500.413726964 error: 0.233\n",
      "i: 10000 cost: 495.87047278 error: 0.228\n",
      "i: 11000 cost: 491.799630404 error: 0.227\n",
      "i: 12000 cost: 488.116955477 error: 0.222\n",
      "i: 13000 cost: 484.757738243 error: 0.222\n",
      "i: 14000 cost: 481.671367823 error: 0.219\n",
      "i: 15000 cost: 478.817640046 error: 0.217\n",
      "i: 16000 cost: 476.16418227 error: 0.22\n",
      "i: 17000 cost: 473.684615388 error: 0.218\n",
      "i: 18000 cost: 471.357215242 error: 0.213\n",
      "i: 19000 cost: 469.163920301 error: 0.211\n",
      "i: 20000 cost: 467.089584398 error: 0.211\n",
      "i: 21000 cost: 465.121406132 error: 0.211\n",
      "i: 22000 cost: 463.248487703 error: 0.21\n",
      "i: 23000 cost: 461.46148999 error: 0.208\n",
      "i: 24000 cost: 459.752360141 error: 0.21\n",
      "i: 25000 cost: 458.114114431 error: 0.209\n",
      "i: 26000 cost: 456.540663724 error: 0.207\n",
      "i: 27000 cost: 455.026672081 error: 0.206\n",
      "i: 28000 cost: 453.567441386 error: 0.206\n",
      "i: 29000 cost: 452.158816598 error: 0.206\n",
      "i: 30000 cost: 450.797107422 error: 0.206\n",
      "i: 31000 cost: 449.479023202 error: 0.205\n",
      "i: 32000 cost: 448.201618499 error: 0.202\n",
      "i: 33000 cost: 446.962247355 error: 0.202\n",
      "i: 34000 cost: 445.758524682 error: 0.2\n",
      "i: 35000 cost: 444.588293517 error: 0.2\n",
      "i: 36000 cost: 443.44959711 error: 0.199\n",
      "i: 37000 cost: 442.340655061 error: 0.199\n",
      "i: 38000 cost: 441.259842816 error: 0.2\n",
      "i: 39000 cost: 440.205673994 error: 0.201\n",
      "i: 40000 cost: 439.176785091 error: 0.201\n",
      "i: 41000 cost: 438.171922212 error: 0.199\n",
      "i: 42000 cost: 437.189929501 error: 0.199\n",
      "i: 43000 cost: 436.229739043 error: 0.196\n",
      "i: 44000 cost: 435.290362006 error: 0.196\n",
      "i: 45000 cost: 434.370880861 error: 0.195\n",
      "i: 46000 cost: 433.470442524 error: 0.194\n",
      "i: 47000 cost: 432.588252293 error: 0.194\n",
      "i: 48000 cost: 431.723568483 error: 0.194\n",
      "i: 49000 cost: 430.875697651 error: 0.193\n",
      "i: 50000 cost: 430.043990351 error: 0.192\n",
      "i: 51000 cost: 429.227837351 error: 0.193\n",
      "i: 52000 cost: 428.426666233 error: 0.192\n",
      "i: 53000 cost: 427.639938367 error: 0.193\n",
      "i: 54000 cost: 426.867146172 error: 0.192\n",
      "i: 55000 cost: 426.107810667 error: 0.192\n",
      "i: 56000 cost: 425.361479253 error: 0.193\n",
      "i: 57000 cost: 424.62772371 error: 0.193\n",
      "i: 58000 cost: 423.906138389 error: 0.193\n",
      "i: 59000 cost: 423.196338561 error: 0.191\n",
      "i: 60000 cost: 422.497958933 error: 0.193\n",
      "i: 61000 cost: 421.810652278 error: 0.193\n",
      "i: 62000 cost: 421.134088201 error: 0.191\n",
      "i: 63000 cost: 420.467952008 error: 0.189\n",
      "i: 64000 cost: 419.811943664 error: 0.187\n",
      "i: 65000 cost: 419.165776849 error: 0.188\n",
      "i: 66000 cost: 418.529178083 error: 0.189\n",
      "i: 67000 cost: 417.901885928 error: 0.189\n",
      "i: 68000 cost: 417.283650249 error: 0.189\n",
      "i: 69000 cost: 416.674231534 error: 0.188\n",
      "i: 70000 cost: 416.07340027 error: 0.188\n",
      "i: 71000 cost: 415.480936357 error: 0.188\n",
      "i: 72000 cost: 414.896628578 error: 0.188\n",
      "i: 73000 cost: 414.320274096 error: 0.187\n",
      "i: 74000 cost: 413.751677994 error: 0.186\n",
      "i: 75000 cost: 413.190652848 error: 0.186\n",
      "i: 76000 cost: 412.637018323 error: 0.186\n",
      "i: 77000 cost: 412.090600805 error: 0.186\n",
      "i: 78000 cost: 411.551233054 error: 0.185\n",
      "i: 79000 cost: 411.018753876 error: 0.185\n",
      "i: 80000 cost: 410.493007825 error: 0.185\n",
      "i: 81000 cost: 409.973844918 error: 0.181\n",
      "i: 82000 cost: 409.461120368 error: 0.179\n",
      "i: 83000 cost: 408.954694338 error: 0.179\n",
      "i: 84000 cost: 408.454431707 error: 0.18\n",
      "i: 85000 cost: 407.960201849 error: 0.18\n",
      "i: 86000 cost: 407.471878428 error: 0.18\n",
      "i: 87000 cost: 406.989339202 error: 0.179\n",
      "i: 88000 cost: 406.512465845 error: 0.179\n",
      "i: 89000 cost: 406.041143769 error: 0.179\n",
      "i: 90000 cost: 405.575261964 error: 0.179\n",
      "i: 91000 cost: 405.114712845 error: 0.178\n",
      "i: 92000 cost: 404.659392105 error: 0.178\n",
      "i: 93000 cost: 404.209198578 error: 0.176\n",
      "i: 94000 cost: 403.764034112 error: 0.174\n",
      "i: 95000 cost: 403.32380344 error: 0.174\n",
      "i: 96000 cost: 402.88841407 error: 0.171\n",
      "i: 97000 cost: 402.457776168 error: 0.172\n",
      "i: 98000 cost: 402.031802459 error: 0.172\n",
      "i: 99000 cost: 401.61040812 error: 0.167\n",
      "i: 100000 cost: 401.193510693 error: 0.167\n",
      "i: 101000 cost: 400.78102999 error: 0.167\n",
      "i: 102000 cost: 400.372888008 error: 0.167\n",
      "i: 103000 cost: 399.969008846 error: 0.168\n",
      "i: 104000 cost: 399.569318632 error: 0.168\n",
      "i: 105000 cost: 399.173745443 error: 0.168\n",
      "i: 106000 cost: 398.782219237 error: 0.168\n",
      "i: 107000 cost: 398.394671787 error: 0.168\n",
      "i: 108000 cost: 398.011036613 error: 0.168\n",
      "i: 109000 cost: 397.631248924 error: 0.168\n",
      "i: 110000 cost: 397.255245556 error: 0.167\n",
      "i: 111000 cost: 396.882964918 error: 0.167\n",
      "i: 112000 cost: 396.514346939 error: 0.167\n",
      "i: 113000 cost: 396.149333014 error: 0.167\n",
      "i: 114000 cost: 395.787865956 error: 0.166\n",
      "i: 115000 cost: 395.42988995 error: 0.165\n",
      "i: 116000 cost: 395.075350505 error: 0.165\n",
      "i: 117000 cost: 394.724194415 error: 0.165\n",
      "i: 118000 cost: 394.376369713 error: 0.164\n",
      "i: 119000 cost: 394.031825636 error: 0.163\n",
      "Mejor Error de validacion: 0.163\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos\n",
    "\n",
    "model = LogisticModel() # instancio un objeto de la clase LogisticModel\n",
    "\n",
    "# hice una pequeña modificacion en el codigo de la clase para que al hacer model.fit() \n",
    "# devuelva los costes segun se ha ido entrenando. \n",
    "lista_costs=model.JEC_fit(X, Y, epochs=120000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87363304981774004"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X, Y)\n",
    "# scores = cross_val_score(model, X, Y, cv=5)\n",
    "# print \"score mean:\", np.mean(scores), \"stdev:\", np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b7621dd10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lista_costs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
